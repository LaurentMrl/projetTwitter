{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réalisation du projet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquisition des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a dans un premier temps utilisé tweepy , scrappy afin de recuperer un maximum de données concernant des tweets, or quelques soucis ce sont posé au niveau de ces librairies.\n",
    "\n",
    "Nous avons donc choisi d'utiliser la librairie request en effectuant des requetes à l'API de twitter directement afin de recupérer des tweets avec leurs métadonnées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Répartition des taches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapping des données twitter : Laurent\n",
    "\n",
    "Preprocessing / création du modèle de NLP : Nolan\n",
    "\n",
    "Applicatif Web : Antoine\n",
    "\n",
    "Réfléxion graphiques : Antoine\n",
    "\n",
    "Tout le monde a néanmoins travaillé sur toute les parties du projet, mais pas dans son intégralité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choix des méthodes d'analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour l'analyse des tweets on'est parti sur du Natural Language Processing, car notre but était de determiner si un tweet etait positif ou négatif. Pour cela on est parti sur des technologies comme pandas, numpy, sklearn, regex, nltk ainsi que spacy pour le preprocessing des données.\n",
    "\n",
    "Pour la parti modèle on'est parti sur un modèle de RandomForestClassifier car c'est l'un des modèles les plus populaires pour fairer du NLP.\n",
    "\n",
    "Afin d'entrainer le modèle nous avons véctorizé ces donnée a l'aide de la méthode Tfidf que l'on a pu voir dans un cours precédant dans notre module de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outils de développement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concernant les outils de développement on'a utilisé :\n",
    "\n",
    "    - Git\n",
    "    - VsCode / Pycharm\n",
    "    - Miniconda3\n",
    "    - Jupyter notebook\n",
    "    - Flask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyses préparatoires et exploiratoires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de préparer les données pour leur exploration, on'a décidé dans un premier temps une fois recupéré de les stocker sous format .csv pour pouvoir les charger avec pandas.\n",
    "\n",
    "Une fois les données récupéré et sauvegardé en .csv il nous a fallu les néttoyer et les normaliser, pour cela on'a dans un premie temps décider à l'aide de regex de remplacer toute la ponctuation par des string vide, tout les underscores ont été rempalacés par des espaces. Par la suite on a mis en minuscule tout notre dataframe pour eviter les probèmes de reconnaissance. On a également retiré tout les stopwords ansi que racinisé toute nos données afin de reduire la quantité de données à analyser et ainsi retirer tout la donnée n'apportant auncune informations utiles. \n",
    "\n",
    "Suite à ca nous avons split nos données en deux parties (train / test) afin de les vectorizer et de pouvoir par la suite train notre modèle afin de pouvoir commencer l'exploration de nos données. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'explorer nos données récupérées en amont nous avons utilisé notre modèle afin de predire l'avis positif ou négatif des tweets. On'a également réalisé des wordcloud afin de voir les mots les plus utilisés en fonction de chaque candidats, on mis en place des graphique avec pathplotlib pour voir le nombre d'avis positif et négatif par rapport aux candidats cités dans les tweets que nous avons récupérés.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}